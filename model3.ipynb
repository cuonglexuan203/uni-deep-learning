{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 224, 224]           4,736\n",
      "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
      "         MaxPool2d-3           [-1, 32, 44, 44]               0\n",
      "            Conv2d-4           [-1, 64, 44, 44]          51,264\n",
      "       BatchNorm2d-5           [-1, 64, 44, 44]             128\n",
      "         AvgPool2d-6           [-1, 64, 11, 11]               0\n",
      "            Conv2d-7          [-1, 128, 11, 11]         204,928\n",
      "            Conv2d-8          [-1, 128, 11, 11]         409,728\n",
      "            Conv2d-9          [-1, 256, 11, 11]         819,456\n",
      "           Conv2d-10          [-1, 256, 11, 11]         819,456\n",
      "           Conv2d-11           [-1, 64, 11, 11]         102,464\n",
      "           Conv2d-12           [-1, 64, 11, 11]         102,464\n",
      "           Conv2d-13          [-1, 256, 11, 11]         409,856\n",
      "           Conv2d-14          [-1, 256, 11, 11]         409,856\n",
      "           Conv2d-15          [-1, 512, 11, 11]       6,554,112\n",
      "           Conv2d-16          [-1, 256, 11, 11]       3,277,056\n",
      "           Conv2d-17           [-1, 64, 11, 11]          36,928\n",
      "           Conv2d-18           [-1, 64, 11, 11]          36,928\n",
      "           Conv2d-19           [-1, 64, 11, 11]          36,928\n",
      "           Conv2d-20           [-1, 64, 11, 11]          36,928\n",
      "           Conv2d-21           [-1, 96, 11, 11]          55,392\n",
      "           Conv2d-22          [-1, 128, 11, 11]         110,720\n",
      "           Conv2d-23          [-1, 128, 11, 11]          73,856\n",
      "           Conv2d-24          [-1, 256, 11, 11]         590,080\n",
      "           Conv2d-25          [-1, 256, 11, 11]         590,080\n",
      "           Conv2d-26          [-1, 256, 11, 11]         590,080\n",
      "AdaptiveAvgPool2d-27            [-1, 512, 3, 3]               0\n",
      "           Linear-28                  [-1, 128]         589,952\n",
      "           Linear-29                   [-1, 64]           8,256\n",
      "           Linear-30                    [-1, 3]             195\n",
      "================================================================\n",
      "Total params: 15,921,891\n",
      "Trainable params: 15,921,891\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 30.24\n",
      "Params size (MB): 60.74\n",
      "Estimated Total Size (MB): 91.55\n",
      "----------------------------------------------------------------\n",
      "[1,    20] loss: 1.155\n",
      "Time: 2.260806083679199\n",
      "[1,    40] loss: 1.096\n",
      "Time: 2.0675642490386963\n",
      "[1,    60] loss: 1.057\n",
      "Time: 2.0925402641296387\n",
      "[1,    80] loss: 0.972\n",
      "Time: 3.0004608631134033\n",
      "[1,   100] loss: 0.987\n",
      "Time: 3.109088897705078\n",
      "[1,   120] loss: 0.923\n",
      "Time: 3.080751419067383\n",
      "[1,   140] loss: 1.001\n",
      "Time: 3.5464582443237305\n",
      "[1,   160] loss: 0.951\n",
      "Time: 3.98502516746521\n",
      "[1,   180] loss: 0.958\n",
      "Time: 4.0476179122924805\n",
      "[2,    20] loss: 0.895\n",
      "Time: 3.8841912746429443\n",
      "[2,    40] loss: 1.018\n",
      "Time: 3.777414321899414\n",
      "[2,    60] loss: 0.982\n",
      "Time: 3.7973108291625977\n",
      "[2,    80] loss: 0.914\n",
      "Time: 3.7818706035614014\n",
      "[2,   100] loss: 0.881\n",
      "Time: 3.7828056812286377\n",
      "[2,   120] loss: 0.835\n",
      "Time: 3.782987356185913\n",
      "[2,   140] loss: 0.858\n",
      "Time: 3.798017978668213\n",
      "[2,   160] loss: 0.933\n",
      "Time: 3.72921085357666\n",
      "[2,   180] loss: 0.902\n",
      "Time: 3.789586067199707\n",
      "[3,    20] loss: 0.971\n",
      "Time: 3.800727128982544\n",
      "[3,    40] loss: 0.772\n",
      "Time: 3.780181646347046\n",
      "[3,    60] loss: 0.632\n",
      "Time: 3.742072105407715\n",
      "[3,    80] loss: 0.694\n",
      "Time: 3.756941556930542\n",
      "[3,   100] loss: 0.754\n",
      "Time: 3.779334545135498\n",
      "[3,   120] loss: 0.698\n",
      "Time: 3.7484254837036133\n",
      "[3,   140] loss: 0.637\n",
      "Time: 3.790872573852539\n",
      "[3,   160] loss: 0.614\n",
      "Time: 3.6812050342559814\n",
      "[3,   180] loss: 0.692\n",
      "Time: 3.807405471801758\n",
      "[4,    20] loss: 0.646\n",
      "Time: 3.7998673915863037\n",
      "[4,    40] loss: 0.568\n",
      "Time: 3.7680304050445557\n",
      "[4,    60] loss: 0.517\n",
      "Time: 3.7734673023223877\n",
      "[4,    80] loss: 0.626\n",
      "Time: 3.775923728942871\n",
      "[4,   100] loss: 0.525\n",
      "Time: 3.8115644454956055\n",
      "[4,   120] loss: 0.524\n",
      "Time: 3.7440247535705566\n",
      "[4,   140] loss: 0.596\n",
      "Time: 3.7651891708374023\n",
      "[4,   160] loss: 0.542\n",
      "Time: 3.8210391998291016\n",
      "[4,   180] loss: 0.471\n",
      "Time: 3.80955171585083\n",
      "[5,    20] loss: 0.417\n",
      "Time: 3.7685887813568115\n",
      "[5,    40] loss: 0.634\n",
      "Time: 3.8409976959228516\n",
      "[5,    60] loss: 0.605\n",
      "Time: 3.7624025344848633\n",
      "[5,    80] loss: 0.446\n",
      "Time: 3.796361207962036\n",
      "[5,   100] loss: 0.623\n",
      "Time: 3.8140759468078613\n",
      "[5,   120] loss: 0.492\n",
      "Time: 3.7853293418884277\n",
      "[5,   140] loss: 0.448\n",
      "Time: 3.8450965881347656\n",
      "[5,   160] loss: 0.442\n",
      "Time: 3.7458760738372803\n",
      "[5,   180] loss: 0.552\n",
      "Time: 3.1184442043304443\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 78 %\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "\n",
    "def train():\n",
    "    # TRANSFORMATION AUGMENTATION\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        # Turn the image into a torch.Tensor\n",
    "        transforms.ToTensor(),  # converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
    "        # ConvFiltersTransform(axis=(1, 2)),\n",
    "        # transforms.Resize(size=(224, 224))\n",
    "    ])\n",
    "\n",
    "    # DATA SETS\n",
    "    train_data = datasets.ImageFolder(root='./dataset/train', transform=data_transform)\n",
    "    test_data = datasets.ImageFolder(root='./dataset/test', transform=data_transform)\n",
    "\n",
    "    # DATA LOADER\n",
    "    train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)\n",
    "\n",
    "    # print(train_data[0][0].shape)  # C, H, W\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv0 = nn.Conv2d(3, 32, kernel_size=7, stride=1, padding=3)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            # Convolutional blocks\n",
    "            self.conv1 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "            # self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "            # Left side\n",
    "            self.conv2 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
    "            self.conv3 = nn.Conv2d(128, 128, kernel_size=5, padding=2)\n",
    "            self.conv4 = nn.Conv2d(128, 256, kernel_size=5, padding=2)\n",
    "            self.conv5 = nn.Conv2d(128, 256, kernel_size=5, padding=2)\n",
    "            # Right side\n",
    "            self.conv6 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
    "            self.conv7 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
    "            self.conv8 = nn.Conv2d(64, 256, kernel_size=5, padding=2)\n",
    "            self.conv9 = nn.Conv2d(64, 256, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "            #\n",
    "            self.conv10 = nn.Conv2d(512, 512, kernel_size=5, padding=2)\n",
    "            self.conv11 = nn.Conv2d(512, 256, kernel_size=5, padding=2)\n",
    "\n",
    "            # Conv3x3\n",
    "            self.conv12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            self.conv13 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            self.conv14 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            self.conv15 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            # Left side\n",
    "            self.conv16 = nn.Conv2d(64, 96, kernel_size=3, padding=1)\n",
    "            self.conv17 = nn.Conv2d(96, 128, kernel_size=3, padding=1)\n",
    "            # Right side\n",
    "            self.conv18 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "            \n",
    "            self.conv19 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "            self.conv20 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "            self.conv21 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "            \n",
    "            # Pooling layers\n",
    "            self.maxpool1 = nn.MaxPool2d(kernel_size=5, stride=5, padding=0)\n",
    "            self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=4, padding=0)\n",
    "            self.avgpool2 = nn.AdaptiveAvgPool2d((3, 3))\n",
    "\n",
    "            # Fully connected layers (for now, we'll keep this as a placeholder)\n",
    "            self.fc1 = nn.Linear(512 * 3 * 3, 128)  # Adjust this later dynamically\n",
    "            self.fc2 = nn.Linear(128, 64)\n",
    "            self.fc3 = nn.Linear(64, 3)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.bn1(self.conv0(x)))\n",
    "\n",
    "            # Pooling\n",
    "            x = self.maxpool1(x)\n",
    "            x = F.relu(self.bn2(self.conv1(x)))\n",
    "            x_avg1 = self.avgpool1(x)\n",
    "            # Branch 5x5\n",
    "            # Left side\n",
    "            x_1 = F.relu(self.conv2(x_avg1))\n",
    "            x_1 = F.relu(self.conv3(x_1))\n",
    "            x_1_L = F.relu(self.conv4(x_1))\n",
    "            x_1_R = F.relu(self.conv5(x_1))\n",
    "            x_1 = F.relu(torch.add(x_1_L, x_1_R))\n",
    "            # Right side\n",
    "            x_2 = F.relu(self.conv6(x_avg1))\n",
    "            x_2 = F.relu(self.conv7(x_2))\n",
    "            x_2_L = F.relu(self.conv8(x_2))\n",
    "            x_2_R = F.relu(self.conv9(x_2))\n",
    "            x_2 = F.relu(torch.add(x_2_L, x_2_R))\n",
    "            #\n",
    "            x_12 = torch.cat((x_1, x_2), 1)\n",
    "            x_12 = F.relu(self.conv10(x_12))\n",
    "            x_12 = F.relu(self.conv11(x_12))\n",
    "            # Branch 3x3\n",
    "            x_3 = F.relu(self.conv12(x_avg1))\n",
    "            x_3 = F.relu(self.conv13(x_3))\n",
    "            x_3 = F.relu(self.conv14(x_3))\n",
    "            x_3 = F.relu(self.conv15(x_3))\n",
    "            x_3_L = F.relu(self.conv16(x_3))\n",
    "            x_3_L = F.relu(self.conv17(x_3_L))\n",
    "            x_3_R = F.relu(self.conv18(x_3))\n",
    "            \n",
    "            x_3 = torch.cat((x_3_L, x_3_R), 1)\n",
    "            x_3 = F.relu(self.conv19(x_3))\n",
    "            x_3 = F.relu(self.conv20(x_3))\n",
    "            x_3 = F.relu(self.conv21(x_3))\n",
    "            \n",
    "            x = torch.cat((x_12, x_3), 1)\n",
    "            x = F.relu(self.avgpool2(x))\n",
    "            \n",
    "            x = x.view(x.size(0), -1)  # Flatten\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            x = self.fc3(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    net = Net()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on: {device}\")\n",
    "\n",
    "    net.to(device)\n",
    "    summary(net, input_size=(3, 224, 224))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    \n",
    "    for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        time_start = time.time()\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 20 == 19:    # print every 20 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 20))\n",
    "                running_loss = 0.0\n",
    "                print('Time:', time.time() - time_start)\n",
    "                time_start = time.time()\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
