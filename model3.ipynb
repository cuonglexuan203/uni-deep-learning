{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 224, 224]           4,736\n",
      "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
      "         MaxPool2d-3           [-1, 32, 44, 44]               0\n",
      "            Conv2d-4           [-1, 64, 44, 44]          51,264\n",
      "       BatchNorm2d-5           [-1, 64, 44, 44]             128\n",
      "         AvgPool2d-6           [-1, 64, 11, 11]               0\n",
      "            Conv2d-7          [-1, 128, 11, 11]         204,928\n",
      "            Conv2d-8          [-1, 128, 11, 11]         409,728\n",
      "            Conv2d-9          [-1, 256, 11, 11]         819,456\n",
      "           Conv2d-10          [-1, 256, 11, 11]         819,456\n",
      "           Conv2d-11           [-1, 64, 11, 11]         102,464\n",
      "           Conv2d-12           [-1, 64, 11, 11]         102,464\n",
      "           Conv2d-13          [-1, 256, 11, 11]         409,856\n",
      "           Conv2d-14          [-1, 256, 11, 11]         409,856\n",
      "           Conv2d-15          [-1, 512, 11, 11]       6,554,112\n",
      "           Conv2d-16          [-1, 256, 11, 11]       3,277,056\n",
      "           Conv2d-17           [-1, 64, 11, 11]          36,928\n",
      "           Conv2d-18           [-1, 64, 11, 11]          36,928\n",
      "           Conv2d-19           [-1, 64, 11, 11]          36,928\n",
      "           Conv2d-20           [-1, 64, 11, 11]          36,928\n",
      "           Conv2d-21           [-1, 96, 11, 11]          55,392\n",
      "           Conv2d-22          [-1, 128, 11, 11]         110,720\n",
      "           Conv2d-23          [-1, 128, 11, 11]          73,856\n",
      "           Conv2d-24          [-1, 256, 11, 11]         590,080\n",
      "           Conv2d-25          [-1, 256, 11, 11]         590,080\n",
      "           Conv2d-26          [-1, 256, 11, 11]         590,080\n",
      "AdaptiveAvgPool2d-27            [-1, 512, 3, 3]               0\n",
      "           Linear-28                  [-1, 128]         589,952\n",
      "           Linear-29                   [-1, 64]           8,256\n",
      "           Linear-30                    [-1, 3]             195\n",
      "================================================================\n",
      "Total params: 15,921,891\n",
      "Trainable params: 15,921,891\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 30.24\n",
      "Params size (MB): 60.74\n",
      "Estimated Total Size (MB): 91.55\n",
      "----------------------------------------------------------------\n",
      "[1,    20] loss: 1.231\n",
      "Time: 2.0501904487609863\n",
      "[1,    40] loss: 1.102\n",
      "Time: 1.8259670734405518\n",
      "[1,    60] loss: 1.120\n",
      "Time: 1.8430309295654297\n",
      "[1,    80] loss: 1.082\n",
      "Time: 1.832766056060791\n",
      "[1,   100] loss: 1.086\n",
      "Time: 1.851529598236084\n",
      "[1,   120] loss: 1.014\n",
      "Time: 1.8757426738739014\n",
      "[1,   140] loss: 0.988\n",
      "Time: 1.8589558601379395\n",
      "[1,   160] loss: 0.977\n",
      "Time: 1.8210363388061523\n",
      "[1,   180] loss: 0.840\n",
      "Time: 1.8297390937805176\n",
      "[2,    20] loss: 0.802\n",
      "Time: 1.8643333911895752\n",
      "[2,    40] loss: 0.819\n",
      "Time: 1.853667974472046\n",
      "[2,    60] loss: 0.673\n",
      "Time: 1.8106133937835693\n",
      "[2,    80] loss: 0.859\n",
      "Time: 1.815495491027832\n",
      "[2,   100] loss: 0.792\n",
      "Time: 1.8021318912506104\n",
      "[2,   120] loss: 0.759\n",
      "Time: 1.808077096939087\n",
      "[2,   140] loss: 0.659\n",
      "Time: 1.8568580150604248\n",
      "[2,   160] loss: 0.728\n",
      "Time: 1.8461060523986816\n",
      "[2,   180] loss: 0.827\n",
      "Time: 1.8566114902496338\n",
      "[3,    20] loss: 0.675\n",
      "Time: 1.8304336071014404\n",
      "[3,    40] loss: 0.624\n",
      "Time: 1.8426823616027832\n",
      "[3,    60] loss: 0.735\n",
      "Time: 1.87209153175354\n",
      "[3,    80] loss: 0.635\n",
      "Time: 1.8243939876556396\n",
      "[3,   100] loss: 0.810\n",
      "Time: 1.8363087177276611\n",
      "[3,   120] loss: 0.739\n",
      "Time: 1.8292415142059326\n",
      "[3,   140] loss: 0.691\n",
      "Time: 1.8339951038360596\n",
      "[3,   160] loss: 0.609\n",
      "Time: 1.8412246704101562\n",
      "[3,   180] loss: 0.609\n",
      "Time: 1.836005687713623\n",
      "[4,    20] loss: 0.723\n",
      "Time: 1.8163480758666992\n",
      "[4,    40] loss: 0.665\n",
      "Time: 1.8413238525390625\n",
      "[4,    60] loss: 0.532\n",
      "Time: 1.8613383769989014\n",
      "[4,    80] loss: 0.670\n",
      "Time: 1.8391048908233643\n",
      "[4,   100] loss: 0.656\n",
      "Time: 1.8436336517333984\n",
      "[4,   120] loss: 0.637\n",
      "Time: 1.8372864723205566\n",
      "[4,   140] loss: 0.461\n",
      "Time: 1.8363053798675537\n",
      "[4,   160] loss: 0.605\n",
      "Time: 1.820369005203247\n",
      "[4,   180] loss: 0.488\n",
      "Time: 1.8253633975982666\n",
      "[5,    20] loss: 0.646\n",
      "Time: 1.8171970844268799\n",
      "[5,    40] loss: 0.502\n",
      "Time: 1.8255681991577148\n",
      "[5,    60] loss: 0.722\n",
      "Time: 1.8659286499023438\n",
      "[5,    80] loss: 0.542\n",
      "Time: 1.8352055549621582\n",
      "[5,   100] loss: 0.451\n",
      "Time: 1.8726327419281006\n",
      "[5,   120] loss: 0.543\n",
      "Time: 1.8597700595855713\n",
      "[5,   140] loss: 0.487\n",
      "Time: 1.8383886814117432\n",
      "[5,   160] loss: 0.467\n",
      "Time: 1.8273389339447021\n",
      "[5,   180] loss: 0.425\n",
      "Time: 1.834702491760254\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 78 %\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "\n",
    "def train():\n",
    "    # TRANSFORMATION AUGMENTATION\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        # Turn the image into a torch.Tensor\n",
    "        transforms.ToTensor(),  # converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
    "        # ConvFiltersTransform(axis=(1, 2)),\n",
    "        # transforms.Resize(size=(224, 224))\n",
    "    ])\n",
    "\n",
    "    # DATA SETS\n",
    "    train_data = datasets.ImageFolder(root='./dataset/train', transform=data_transform)\n",
    "    test_data = datasets.ImageFolder(root='./dataset/test', transform=data_transform)\n",
    "\n",
    "    # DATA LOADER\n",
    "    train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)\n",
    "\n",
    "    # print(train_data[0][0].shape)  # C, H, W\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv0 = nn.Conv2d(3, 32, kernel_size=7, stride=1, padding=3)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            # Convolutional blocks\n",
    "            self.conv1 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "            # self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "            # Left side\n",
    "            self.conv2 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
    "            self.conv3 = nn.Conv2d(128, 128, kernel_size=5, padding=2)\n",
    "            self.conv4 = nn.Conv2d(128, 256, kernel_size=5, padding=2)\n",
    "            self.conv5 = nn.Conv2d(128, 256, kernel_size=5, padding=2)\n",
    "            # Right side\n",
    "            self.conv6 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
    "            self.conv7 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
    "            self.conv8 = nn.Conv2d(64, 256, kernel_size=5, padding=2)\n",
    "            self.conv9 = nn.Conv2d(64, 256, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "            #\n",
    "            self.conv10 = nn.Conv2d(512, 512, kernel_size=5, padding=2)\n",
    "            self.conv11 = nn.Conv2d(512, 256, kernel_size=5, padding=2)\n",
    "\n",
    "            # Conv3x3\n",
    "            self.conv12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            self.conv13 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            self.conv14 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            self.conv15 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            # Left side\n",
    "            self.conv16 = nn.Conv2d(64, 96, kernel_size=3, padding=1)\n",
    "            self.conv17 = nn.Conv2d(96, 128, kernel_size=3, padding=1)\n",
    "            # Right side\n",
    "            self.conv18 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "            \n",
    "            self.conv19 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "            self.conv20 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "            self.conv21 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "            \n",
    "            # Pooling layers\n",
    "            self.maxpool1 = nn.MaxPool2d(kernel_size=5, stride=5, padding=0)\n",
    "            self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=4, padding=0)\n",
    "            self.avgpool2 = nn.AdaptiveAvgPool2d((3, 3))\n",
    "\n",
    "            # Fully connected layers (for now, we'll keep this as a placeholder)\n",
    "            self.fc1 = nn.Linear(512 * 3 * 3, 128)  # Adjust this later dynamically\n",
    "            self.fc2 = nn.Linear(128, 64)\n",
    "            self.fc3 = nn.Linear(64, 3)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.bn1(self.conv0(x)))\n",
    "\n",
    "            # Pooling\n",
    "            x = self.maxpool1(x)\n",
    "            x = F.relu(self.bn2(self.conv1(x)))\n",
    "            x_avg1 = self.avgpool1(x)\n",
    "            # Branch 5x5\n",
    "            # Left side\n",
    "            x_1 = F.relu(self.conv2(x_avg1))\n",
    "            x_1 = F.relu(self.conv3(x_1))\n",
    "            x_1_L = F.relu(self.conv4(x_1))\n",
    "            x_1_R = F.relu(self.conv5(x_1))\n",
    "            x_1 = F.relu(torch.add(x_1_L, x_1_R))\n",
    "            # Right side\n",
    "            x_2 = F.relu(self.conv6(x_avg1))\n",
    "            x_2 = F.relu(self.conv7(x_2))\n",
    "            x_2_L = F.relu(self.conv8(x_2))\n",
    "            x_2_R = F.relu(self.conv9(x_2))\n",
    "            x_2 = F.relu(torch.add(x_2_L, x_2_R))\n",
    "            #\n",
    "            x_12 = torch.cat((x_1, x_2), 1)\n",
    "            x_12 = F.relu(self.conv10(x_12))\n",
    "            x_12 = F.relu(self.conv11(x_12))\n",
    "            # Branch 3x3\n",
    "            x_3 = F.relu(self.conv12(x_avg1))\n",
    "            x_3 = F.relu(self.conv13(x_3))\n",
    "            x_3 = F.relu(self.conv14(x_3))\n",
    "            x_3 = F.relu(self.conv15(x_3))\n",
    "            x_3_L = F.relu(self.conv16(x_3))\n",
    "            x_3_L = F.relu(self.conv17(x_3_L))\n",
    "            x_3_R = F.relu(self.conv18(x_3))\n",
    "            \n",
    "            x_3 = torch.cat((x_3_L, x_3_R), 1)\n",
    "            x_3 = F.relu(self.conv19(x_3))\n",
    "            x_3 = F.relu(self.conv20(x_3))\n",
    "            x_3 = F.relu(self.conv21(x_3))\n",
    "            \n",
    "            x = torch.cat((x_12, x_3), 1)\n",
    "            x = F.relu(self.avgpool2(x))\n",
    "            \n",
    "            x = x.view(x.size(0), -1)  # Flatten\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            x = self.fc3(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    net = Net()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on: {device}\")\n",
    "\n",
    "    net.to(device)\n",
    "    summary(net, input_size=(3, 224, 224))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    \n",
    "    for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        time_start = time.time()\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 20 == 19:    # print every 20 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 20))\n",
    "                running_loss = 0.0\n",
    "                print('Time:', time.time() - time_start)\n",
    "                time_start = time.time()\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
