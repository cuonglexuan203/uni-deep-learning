{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 224, 224]           4,736\n",
      "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
      "         MaxPool2d-3           [-1, 32, 44, 44]               0\n",
      "            Conv2d-4           [-1, 64, 44, 44]          51,264\n",
      "       BatchNorm2d-5           [-1, 64, 44, 44]             128\n",
      "         MaxPool2d-6             [-1, 64, 8, 8]               0\n",
      "            Conv2d-7            [-1, 128, 8, 8]         204,928\n",
      "            Conv2d-8            [-1, 128, 8, 8]         409,728\n",
      "            Conv2d-9            [-1, 256, 8, 8]         819,456\n",
      "           Conv2d-10            [-1, 256, 8, 8]         819,456\n",
      "           Conv2d-11             [-1, 64, 8, 8]         102,464\n",
      "           Conv2d-12            [-1, 256, 8, 8]       1,229,056\n",
      "           Conv2d-13            [-1, 256, 8, 8]       1,229,056\n",
      "           Conv2d-14            [-1, 512, 8, 8]       6,554,112\n",
      "           Conv2d-15            [-1, 512, 6, 6]       6,554,112\n",
      "AdaptiveAvgPool2d-16            [-1, 512, 3, 3]               0\n",
      "           Linear-17                   [-1, 32]         147,488\n",
      "           Linear-18                    [-1, 3]              99\n",
      "================================================================\n",
      "Total params: 18,126,147\n",
      "Trainable params: 18,126,147\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 27.98\n",
      "Params size (MB): 69.15\n",
      "Estimated Total Size (MB): 97.70\n",
      "----------------------------------------------------------------\n",
      "[1,    20] loss: 4.127\n",
      "Time: 1.957179069519043\n",
      "[1,    40] loss: 1.117\n",
      "Time: 1.581803798675537\n",
      "[1,    60] loss: 1.090\n",
      "Time: 1.6376893520355225\n",
      "[1,    80] loss: 1.066\n",
      "Time: 1.6114938259124756\n",
      "[1,   100] loss: 1.018\n",
      "Time: 1.580806016921997\n",
      "[1,   120] loss: 1.029\n",
      "Time: 1.5724804401397705\n",
      "[1,   140] loss: 1.102\n",
      "Time: 1.5848777294158936\n",
      "[1,   160] loss: 1.071\n",
      "Time: 1.5502583980560303\n",
      "[1,   180] loss: 1.099\n",
      "Time: 1.6073992252349854\n",
      "[2,    20] loss: 1.102\n",
      "Time: 1.6971957683563232\n",
      "[2,    40] loss: 1.089\n",
      "Time: 1.6548633575439453\n",
      "[2,    60] loss: 1.031\n",
      "Time: 1.6416850090026855\n",
      "[2,    80] loss: 0.956\n",
      "Time: 1.589355707168579\n",
      "[2,   100] loss: 0.951\n",
      "Time: 1.6064610481262207\n",
      "[2,   120] loss: 0.880\n",
      "Time: 1.6147823333740234\n",
      "[2,   140] loss: 0.805\n",
      "Time: 1.5807721614837646\n",
      "[2,   160] loss: 0.786\n",
      "Time: 1.6900618076324463\n",
      "[2,   180] loss: 0.743\n",
      "Time: 1.5655007362365723\n",
      "[3,    20] loss: 0.650\n",
      "Time: 1.6760005950927734\n",
      "[3,    40] loss: 0.808\n",
      "Time: 1.6419799327850342\n",
      "[3,    60] loss: 0.622\n",
      "Time: 1.5676615238189697\n",
      "[3,    80] loss: 0.742\n",
      "Time: 1.545752763748169\n",
      "[3,   100] loss: 0.588\n",
      "Time: 1.5763728618621826\n",
      "[3,   120] loss: 0.580\n",
      "Time: 1.620978832244873\n",
      "[3,   140] loss: 0.722\n",
      "Time: 1.5989320278167725\n",
      "[3,   160] loss: 0.614\n",
      "Time: 1.5844779014587402\n",
      "[3,   180] loss: 0.615\n",
      "Time: 1.5896797180175781\n",
      "[4,    20] loss: 0.629\n",
      "Time: 1.6828975677490234\n",
      "[4,    40] loss: 0.641\n",
      "Time: 1.8962724208831787\n",
      "[4,    60] loss: 0.537\n",
      "Time: 2.2813291549682617\n",
      "[4,    80] loss: 0.560\n",
      "Time: 2.5076558589935303\n",
      "[4,   100] loss: 0.617\n",
      "Time: 2.266491651535034\n",
      "[4,   120] loss: 0.713\n",
      "Time: 1.5676662921905518\n",
      "[4,   140] loss: 0.550\n",
      "Time: 1.6225838661193848\n",
      "[4,   160] loss: 0.581\n",
      "Time: 1.616743803024292\n",
      "[4,   180] loss: 0.579\n",
      "Time: 1.6551191806793213\n",
      "[5,    20] loss: 0.549\n",
      "Time: 1.596536636352539\n",
      "[5,    40] loss: 0.485\n",
      "Time: 2.045063018798828\n",
      "[5,    60] loss: 0.585\n",
      "Time: 2.422058582305908\n",
      "[5,    80] loss: 0.561\n",
      "Time: 2.4338648319244385\n",
      "[5,   100] loss: 0.478\n",
      "Time: 2.4578380584716797\n",
      "[5,   120] loss: 0.629\n",
      "Time: 2.5032458305358887\n",
      "[5,   140] loss: 0.537\n",
      "Time: 2.4818410873413086\n",
      "[5,   160] loss: 0.544\n",
      "Time: 2.44305419921875\n",
      "[5,   180] loss: 0.578\n",
      "Time: 2.4300379753112793\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "\n",
    "def train():\n",
    "    # TRANSFORMATION AUGMENTATION\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        # Turn the image into a torch.Tensor\n",
    "        transforms.ToTensor(),  # converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
    "        # ConvFiltersTransform(axis=(1, 2)),\n",
    "        # transforms.Resize(size=(224, 224))\n",
    "    ])\n",
    "\n",
    "    # DATA SETS\n",
    "    train_data = datasets.ImageFolder(root='./dataset/train', transform=data_transform)\n",
    "    test_data = datasets.ImageFolder(root='./dataset/test', transform=data_transform)\n",
    "\n",
    "    # DATA LOADER\n",
    "    train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)\n",
    "\n",
    "    # print(train_data[0][0].shape)  # C, H, W\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=1, padding=3)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            # Convolutional blocks\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "            # self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "            self.conv3_1 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
    "            self.conv3_2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
    "            # Left side\n",
    "            self.conv4 = nn.Conv2d(128, 128, kernel_size=5, padding=2)\n",
    "            self.conv5 = nn.Conv2d(128, 256, kernel_size=5, padding=2)\n",
    "            self.conv6 = nn.Conv2d(128, 256, kernel_size=5, padding=2)\n",
    "            # Right side\n",
    "            self.conv7 = nn.Conv2d(192, 256, kernel_size=5, padding=2)\n",
    "            self.conv8 = nn.Conv2d(192, 256, kernel_size=5, padding=2)\n",
    "\n",
    "            #\n",
    "            self.conv9 = nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2)\n",
    "            self.conv10 = nn.Conv2d(512, 512, kernel_size=5, padding=1)\n",
    "\n",
    "            # Pooling layers\n",
    "            self.maxpool1 = nn.MaxPool2d(kernel_size=5, stride=5, padding=0)\n",
    "            self.maxpool2 = nn.MaxPool2d(kernel_size=5, stride=5, padding=0)\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d((3, 3))\n",
    "\n",
    "            # Fully connected layers (for now, we'll keep this as a placeholder)\n",
    "            self.fc1 = nn.Linear(512 * 3 * 3, 32)  # Adjust this later dynamically\n",
    "            self.fc6 = nn.Linear(32, 3)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "            # Pooling\n",
    "            x = self.maxpool1(x)\n",
    "            x = F.relu(self.bn2(self.conv2(x)))\n",
    "            x = self.maxpool2(x)\n",
    "            # Left side\n",
    "            x_1 = F.relu(self.conv3_1(x))\n",
    "            x_L = F.relu(self.conv4(x_1))\n",
    "            x_L_1 = F.relu(self.conv5(x_L))\n",
    "            x_L_2 = F.relu(self.conv6(x_L))\n",
    "            x_L = F.relu(torch.add(x_L_1, x_L_2))\n",
    "            # Right side\n",
    "            x_2 = F.relu(self.conv3_2(x))\n",
    "            x_R = torch.cat((x_1, x_2), 1)\n",
    "            x_R_1 = F.relu(self.conv7(x_R))\n",
    "            x_R_2 = F.relu(self.conv8(x_R))\n",
    "            x_R = F.relu(torch.add(x_R_1, x_R_2))\n",
    "            #\n",
    "            x = torch.cat((x_L, x_R), 1)\n",
    "            x = F.relu(self.conv9(x))\n",
    "            x = F.relu(self.conv10(x))\n",
    "            x = F.relu(self.avgpool(x))\n",
    "            #\n",
    "            \n",
    "            x = x.view(x.size(0), -1)  # Flatten\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc6(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    net = Net()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on: {device}\")\n",
    "\n",
    "    net.to(device)\n",
    "    summary(net, input_size=(3, 224, 224))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    \n",
    "    for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        time_start = time.time()\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 20 == 19:    # print every 20 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 20))\n",
    "                running_loss = 0.0\n",
    "                print('Time:', time.time() - time_start)\n",
    "                time_start = time.time()\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
